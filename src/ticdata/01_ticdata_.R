rm(list=ls())

setwd("//media//kswada//MyFiles//R//ticdata")

packages <- c("dplyr", "caret", "AppliedPredictiveModeling")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)



# ------------------------------------------------------------------------------
# data:  ticdata
#   - data set generated by the computational intelligence and learning (CoIL) research network.
#     The 2000 CoIL Challenge was to predict whether customers would purchase caravan insurance; Van Der Putten and Van Someren (2004)
#     discuss these data, the challenge, and some of the solutions to the problem.
#   - The outcome, whether the consumer purchased caravan insurance, is highly unbalanced with only 6% of customers having purchased policies.
#   - The predictors in the data set consisted of:
#        - Customer subtype designation, such as "Traditional Families" or "Affluent Young Families." There were 39 unique values,
#          although many of the subtypes comprise less than 5% of the customers.
#        - Demographic factors, such as religion, education level, social class, income, and 38 others. The values of the predictors were derived
#          from data at the zip code level, so customers residing in the same zip code will have the same values for these attributes.
#        - Product ownership information, such as the number of (or the contribution to) policies of various types.
#        - In all there were 85 predictors. Many of the categorical predictors had 10 or more levels and the count-based predictors tended to be fairly sparse.
#          (i.e., few nonzero values)
# ------------------------------------------------------------------------------
library(DWD)

data(ticdata)

str(ticdata)



# ------------------------------------------------------------------------------
# Cleansing predictors
# ------------------------------------------------------------------------------
# Some of the predictor names and levels have characters that would results in illegal variable names.
# We convert then to more generic names and treat the ordered factors as nominal (i.e. unordered) factors. 

isOrdered <- unlist(lapply(ticdata, function(x) any(class(x) == "ordered")))

recodeLevels <- function(x)
{
  x <- gsub("f ", "", as.character(x))
  x <- gsub(" - ", "_to_", x)
  x <- gsub("-", "_to_", x)
  x <- gsub("%", "", x)
  x <- gsub("?", "Unk", x, fixed = TRUE)
  x <- gsub("[,'\\(\\)]", "", x)
  x <- gsub(" ", "_", x)
  factor(paste("_", x, sep = ""))
}

convertCols <- c("STYPE", "MGEMLEEF", "MOSHOOFD", names(isOrdered)[isOrdered])

for(i in convertCols) ticdata[,i] <- factor(gsub(" ", "0",format(as.numeric(ticdata[,i]))))


# make the level "insurance" the first factor level
ticdata$CARAVAN <- factor(as.character(ticdata$CARAVAN), levels = rev(levels(ticdata$CARAVAN)))


str(ticdata)



# ------------------------------------------------------------------------------
# Split data
#   - Split the data into three sets: training, test and evaluation. 
# ------------------------------------------------------------------------------
# Split data to training and others
set.seed(156)

split1 <- createDataPartition(ticdata$CARAVAN, p = .7)[[1]]

other     <- ticdata[-split1,]
training  <- ticdata[ split1,]



# ----------
# Split other to test and evaluation
set.seed(934)

split2 <- createDataPartition(other$CARAVAN, p = 1/3)[[1]]

evaluation  <- other[ split2,]
testing     <- other[-split2,]



# ----------
# A training set of customers (6877) that will be used to estimate odel parameters, tuning models, etc.
nrow(training)
table(training$CARAVAN) / nrow(training)


# A small evaluation set of customers (n = 983) that will be used for developing post-processing techniques, such as alternative probability cutoffs
nrow(evaluation)
table(evaluation$CARAVAN) / nrow(evaluation)


# A customer test set (n = 1962) that is solely used for final evaluations of the models 
nrow(testing)
table(testing$CARAVAN) / nrow(testing)


# -->
# The rate of customers with caravan policies in each of these data sets was roughly same across all three data sets.



# ------------------------------------------------------------------------------
# predictors and labels
# ------------------------------------------------------------------------------
predictors <- names(training)[names(training) != "CARAVAN"]



# ----------
# results (label)
testResults <- data.frame(CARAVAN = testing$CARAVAN)
evalResults <- data.frame(CARAVAN = evaluation$CARAVAN)



# ------------------------------------------------------------------------------
# Convert to dummy variable data frame
#   - The randomForest function has a limitation that all factor predictors must not have more than 32 levels.
#     The customer type predictor has 39 levels, so a predictor set of dummy variables is created .
# ------------------------------------------------------------------------------
trainingInd <- data.frame(model.matrix(CARAVAN ~ ., data = training))[,-1]
evaluationInd <- data.frame(model.matrix(CARAVAN ~ ., data = evaluation))[,-1]
testingInd <- data.frame(model.matrix(CARAVAN ~ ., data = testing))[,-1]


# add the outcome back into the data set
trainingInd$CARAVAN <- training$CARAVAN
evaluationInd$CARAVAN <- evaluation$CARAVAN
testingInd$CARAVAN <- testing$CARAVAN



# ------------------------------------------------------------------------------
# noNZVSet is required for logistic regression
# determine a predictor set without highly sparse and unbalanced distributions
# ------------------------------------------------------------------------------
isNZV <- nearZeroVar(trainingInd)
noNZVSet <- names(trainingInd)[-isNZV]



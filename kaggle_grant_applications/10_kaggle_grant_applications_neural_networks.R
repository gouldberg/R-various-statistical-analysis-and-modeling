# rm(list=ls())

setwd("//media//kswada//MyFiles//R//kaggle_grant_applications")

packages <- c("dplyr", "caret", "pROC", "nnet")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)



# ----------
library(doMC)
cores <- 20
registerDoMC(cores)



# ----------
load(file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/training")
load(file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/testing")
load(file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/fullSet")
load(file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/reducedSet")
load(file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/pre2008")



# ------------------------------------------------------------------------------
# Set train control
# ------------------------------------------------------------------------------
# This control object will be used across multiple models so that the data splitting is consistent
# Train must know exactly which samples to use when estimating parameters.
# The "index" argument to trainControl identifies these samples. For any sampling method, a set of holdout samples can be exactly specified.
# For example, with 10-fold cross-validation, the exact samples to be excluded for each of the 10-folds are identified with this option.
ctrl <- trainControl(method = "LGOCV",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE,
                     index = list(TrainSet = pre2008),
                     savePredictions = TRUE)



# ------------------------------------------------------------------------------
# Nonlinear Classification Models:  Neural Networks
#
#   - Instead of a single output for regression, the bottom layer has multiple nodes for each class for classification.
#   - For regression, the neural network optimize the sum of the squared erros to find appropriate parameter. Alternatively, for classification,
#     parameter estimates can be found that can maximize the likelihood of the Bernoulli distribution, which corresponds to a binomial likelihood funciton.
#     (entropy or cross-entropy)
#     The likelihood has more theoretical validity than the squared error approach, altough studies have shown that differences in performance tend to be
#     negligible (Kline and berardi 2005). However Bishop (1995) suggests that the entropy function should more accurately estimate small probabilities
#     than those generated by the sqaured-error function.
#   - Collinearity and non-informative predictors will have a comparable impact on model performance.
# ------------------------------------------------------------------------------

# Four different models are evaluate based on the data pre-processing and whethera single or multiple models are used

nnetGrid <- expand.grid(size = 1:10, decay = c(0, .1, 1, 2))

maxSize <- max(nnetGrid$size)


# ----------
set.seed(476)

nnetFit <- train(x = training[,reducedSet], y = training$Class, method = "nnet", metric = "ROC", 
                 preProc = c("center", "scale"), 
                 tuneGrid = nnetGrid, trace = FALSE, maxit = 2000,
                 MaxNWts = 1*(maxSize * (length(reducedSet) + 1) + maxSize + 1), trControl = ctrl)

nnetFit

plot(nnetFit)



# ----------
# Apply spatial sign transformation
set.seed(476)

nnetFit2 <- train(x = training[,reducedSet], y = training$Class, method = "nnet", metric = "ROC", 
                 preProc = c("center", "scale", "spatialSign"), 
                 tuneGrid = nnetGrid, trace = FALSE, maxit = 2000,
                 MaxNWts = 1*(maxSize * (length(reducedSet) + 1) + maxSize + 1), trControl = ctrl)

nnetFit2

plot(nnetFit2)



# ----------
# Model averaging
nnetGrid$bag <- FALSE

set.seed(476)

nnetFit3 <- train(x = training[,reducedSet], y = training$Class, method = "avNNet", metric = "ROC", 
                  preProc = c("center", "scale"), 
                  tuneGrid = nnetGrid, repeats = 10, trace = FALSE, maxit = 2000,
                  MaxNWts = 1*(maxSize * (length(reducedSet) + 1) + maxSize + 1), allowParallel = TRUE, trControl = ctrl)

nnetFit3

plot(nnetFit3)



# ----------
# Spatial sign transformation + model averaging
set.seed(476)

nnetFit4 <- train(x = training[,reducedSet], y = training$Class, method = "avNNet", metric = "ROC", 
                  preProc = c("center", "scale", "spatialSign"), 
                  tuneGrid = nnetGrid, repeats = 10, trace = FALSE, maxit = 2000,
                  MaxNWts = 1*(maxSize * (length(reducedSet) + 1) + maxSize + 1), allowParallel = TRUE, trControl = ctrl)

nnetFit4


plot(nnetFit4)



# ----------
# ROC each for Hidden Units * Weight Decay by Model + Transformation
nnet1 <- nnetFit$results
nnet1$Transform <- "No Transformation"
nnet1$Model <- "Single Model"

nnet2 <- nnetFit2$results
nnet2$Transform <- "Spatial Sign"
nnet2$Model <- "Single Model"

nnet3 <- nnetFit3$results
nnet3$Transform <- "No Transformation"
nnet3$Model <- "Model Averaging"
nnet3$bag <- NULL

nnet4 <- nnetFit4$results
nnet4$Transform <- "Spatial Sign"
nnet4$Model <- "Model Averaging"
nnet4$bag <- NULL

nnetResults <- rbind(nnet1, nnet2, nnet3, nnet4)
nnetResults$Model <- factor(as.character(nnetResults$Model), levels = c("Single Model", "Model Averaging"))

library(latticeExtra)
useOuterStrips(
  xyplot(ROC ~ size | Model * Transform, data = nnetResults,
         groups = decay, as.table = TRUE,
         type = c("p", "l", "g"), lty = 1,
         ylab = "ROC AUC (2008 Hold-Out Data)",
         xlab = "Number of Hidden Units",
         auto.key = list(columns = 4, title = "Weight Decay", cex.title = 1)))


# -->
# The spatial sign transformation had a significant positive impact on the performance of the neural networks for these data.
# However, performance appears to be optimized when using both model averaging and the spatial sign.


# ----------
# confusion matrix and other statistics
confusionMatrix(nnetFit, norm = "none")
confusionMatrix(nnetFit2, norm = "none")
confusionMatrix(nnetFit3, norm = "none")
confusionMatrix(nnetFit4, norm = "none")



# ----------
# ROC Curve
nnetFit$pred <- merge(nnetFit$pred,  nnetFit$bestTune)
nnetFit2$pred <- merge(nnetFit2$pred,  nnetFit2$bestTune)
nnetFit3$pred <- merge(nnetFit3$pred,  nnetFit3$bestTune)
nnetFit4$pred <- merge(nnetFit4$pred,  nnetFit4$bestTune)

nnet_roc <- pROC::roc(response = nnetFit$pred$obs, predictor = nnetFit$pred$successful, levels = rev(levels(nnetFit$pred$obs)))
nnet2_roc <- pROC::roc(response = nnetFit2$pred$obs, predictor = nnetFit2$pred$successful, levels = rev(levels(nnetFit2$pred$obs)))
nnet3_roc <- pROC::roc(response = nnetFit3$pred$obs, predictor = nnetFit3$pred$successful, levels = rev(levels(nnetFit3$pred$obs)))
nnet4_roc <- pROC::roc(response = nnetFit4$pred$obs, predictor = nnetFit4$pred$successful, levels = rev(levels(nnetFit4$pred$obs)))


# plot(glmn_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "darkgray")
# plot(spLDA_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "darkgray")
plot(nnet_roc, type = "s", legacy.axes = TRUE, col = "darkgray")
plot(nnet2_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "red")
plot(nnet3_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "blue")
plot(nnet4_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "black")

auc(nnet_roc);  auc(nnet2_roc);  auc(nnet3_roc);  auc(nnet4_roc);
ci(nnet_roc);  ci(nnet2_roc);  ci(nnet3_roc);  ci(nnet4_roc);



# ----------
# variable importance
plot(varImp(nnetFit4, scale = FALSE), top=20, scales = list(y = list(cex = .95)))



# ------------------------------------------------------------------------------
# model by nnet
# ------------------------------------------------------------------------------
set.seed(800)

# Note that we can not train nnet by full reducedSet, due to too many weights.
#  --> we use only a part of reducedSet

# The nnet package has both a formula interface and an interface for passing matrices or data frames for the predictors and the outcome.
# For the latter, the outcome cannnot be a factor variable and must be converted to a set of C binary indicators by "class.ind" function.
nnetMod <- nnet(x = training[pre2008, reducedSet[1:100]], y = class.ind(training[pre2008, "Class"]), 
                entropy = TRUE, lineout = FALSE, maxit = 1000, size = 7, decay = 0.1)


summary(nnetMod)


predict(nnetMod, newdata = head(training[-pre2008, reducedSet[1:100]]))

predict(nnetMod, newdata = head(training[-pre2008, reducedSet[1:100]]), type = "class")



# ------------------------------------------------------------------------------
# prediction for hold-out data
# ------------------------------------------------------------------------------
nrow(training[-pre2008,])

nnet_ho_pred_prob <- predict(nnetFit4, newdata = training[-pre2008, reducedSet], type ="prob")
nnet_ho_pred <- predict(nnetFit4, newdata = training[-pre2008, reducedSet], type ="raw")

head(nnet_ho_pred_prob, 20)



# ----------
# ROC Curve of predictions for hold-out data
nnet_ho_roc <- pROC::roc(response = training[-pre2008, "Class"], predictor = nnet_ho_pred_prob[,"successful"], levels = rev(levels(training$Class)))

# plot(lda_ho_roc, legacy.axes = TRUE, col = "darkgray")
# plot(pls_red_ho_roc, legacy.axes = TRUE, add = TRUE, col = "red")
# plot(glmn_ho_roc, legacy.axes = TRUE, add = TRUE, col = "blue")
# plot(spLDA_ho_roc, legacy.axes = TRUE, add = TRUE, col = "tan")
# plot(nsc_ho_roc, legacy.axes = TRUE, add = TRUE, col = "black")

plot(nnet_ho_roc, legacy.axes = TRUE, col = "black")

# pROC::auc(lda_ho_roc)
# pROC::auc(pls_red_ho_roc)
# pROC::auc(glmn_ho_roc)
# pROC::auc(spLDA_ho_roc)
# pROC::auc(nsc_ho_roc)
pROC::auc(nnet_ho_roc)


# -->
# AUC by Neural Network model for hold-out data:  0.XXXX



# ------------------------------------------------------------------------------
# diagnose model fit
# ------------------------------------------------------------------------------
testRes_nnet <- data.frame(obs = training[-pre2008, "Class"], nnet_ho_pred_prob = nnet_ho_pred_prob$successful, nnet_ho_pred = nnet_ho_pred)



# ----------
# Plot the probability of successful/unsuccessful applications
histogram( ~ nnet_ho_pred_prob | obs, data = testRes_nnet,
           layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")

